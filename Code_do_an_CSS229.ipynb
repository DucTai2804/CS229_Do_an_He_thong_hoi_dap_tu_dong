{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0JhKzjwMeYf",
        "outputId": "264fa67b-b4df-461f-9b36-c65bab57947c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJpID6WhoaEo",
        "outputId": "20de8981-133c-4bcb-f658-1f5e109c6a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swi-prolog is already the newest version (8.4.2+dfsg-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "ƒê√£ c√†i xong SWI-Prolog\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swi-prolog is already the newest version (8.4.2+dfsg-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "ƒê√£ c√†i xong SWI-Prolog\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install swi-prolog\n",
        "print(\"ƒê√£ c√†i xong SWI-Prolog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT1sPXwfojP8",
        "outputId": "c32f6e7f-e6de-4dd1-ef6a-89e48a766463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting engine.pl\n"
          ]
        }
      ],
      "source": [
        "%%writefile engine.pl\n",
        ":- op(950, yfx, @).\n",
        ":- op(900, yfx, x).\n",
        "\n",
        "% --- REDUCTION DRIVER ---\n",
        "reduce_fully(Term, Final) :-\n",
        "    step(Term, Next), !, reduce_fully(Next, Final).\n",
        "reduce_fully(Term, Term).\n",
        "\n",
        "% --- STEPS ---\n",
        "step(lambda(X, Body) @ Arg, Result) :- substitute(Body, X, Arg, Result).\n",
        "step(drs(R1, C1) x drs(R2, C2), drs(R, C)) :- append(R1, R2, R), append(C1, C2, C).\n",
        "\n",
        "% Traversal\n",
        "step(A x B, ResA x B) :- step(A, ResA).\n",
        "step(A x B, A x ResB) :- step(B, ResB).\n",
        "step(A @ B, ResA @ B) :- step(A, ResA).\n",
        "step(A @ B, A @ ResB) :- step(B, ResB).\n",
        "\n",
        "% --- SUBSTITUTE ---\n",
        "substitute(Term, Old, New, New) :- Term == Old, !.\n",
        "substitute(Term, _, _, Term) :- var(Term), !.\n",
        "substitute(Term, _, _, Term) :- atomic(Term), !.\n",
        "substitute(Term, Old, New, Result) :-\n",
        "    Term =.. [F | Args],\n",
        "    maplist(substitute_helper(Old, New), Args, NewArgs),\n",
        "    Result =.. [F | NewArgs].\n",
        "substitute_helper(Old, New, Arg, Res) :- substitute(Arg, Old, New, Res)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR6xgAu3okxq",
        "outputId": "046b8722-d0be-4a57-c84f-ec038185a26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting facts.pl\n"
          ]
        }
      ],
      "source": [
        "%%writefile facts.pl\n",
        ":- discontiguous thich/2.\n",
        ":- discontiguous co/2.\n",
        ":- discontiguous nhan_vien/2.\n",
        ":- discontiguous ban_dl/2.\n",
        ":- discontiguous anh/1.\n",
        ":- discontiguous la/2.\n",
        "la(X, X).\n",
        "\n",
        "% 1. TH·ª∞C TH·ªÇ\n",
        "cong_ty(samsung).\n",
        "tap_doan(apple).\n",
        "dien_thoai(iphone).\n",
        "\n",
        "% 2. GI·ªöI T√çNH\n",
        "anh(tu).\n",
        "anh(nghia).\n",
        "\n",
        "% 3. QUAN H·ªÜ\n",
        "nhan_vien(tu, samsung).\n",
        "nhan_vien(nghia, apple).\n",
        "ban_dl(tu, nghia).\n",
        "ghet(tu, nghia).\n",
        "thich(tu, iphone).\n",
        "co(nghia, iphone).\n",
        "\n",
        "% 4. QUY T·∫ÆC SUY DI·ªÑN\n",
        "ban(X, Y) :- ban_dl(X, Y).\n",
        "ban(X, Y) :- ban_dl(Y, X).\n",
        "thich(X, iphone) :- co(X, iphone).\n",
        "\n",
        "% 5. H·ªñ TR·ª¢ C√ÇU H·ªéI\n",
        "question_target(_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGoWVg7Mb3JV",
        "outputId": "c6193c35-7aeb-41a4-92f4-a4d4cab4d4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting grammar.pl\n"
          ]
        }
      ],
      "source": [
        "%%writefile grammar.pl\n",
        ":- ensure_loaded('engine.pl').\n",
        "\n",
        "% --- VƒÇN B·∫¢N ---\n",
        "txt(Sem) --> s(Sem).\n",
        "txt(Sem) --> s(S1), txt(S2), { Sem = (S1 x S2) }.\n",
        "\n",
        "% --- C√ÇU ---\n",
        "s(Sem) --> np(NP), vp(VP), { Sem = (NP @ VP) }.\n",
        "\n",
        "% --- C·ª§M DANH T·ª™ (NP) ---\n",
        "% 1. T√™n ri√™ng & T·ª´ h·ªèi\n",
        "np(Sem) --> nnp(Sem).\n",
        "np(Sem) --> wp_pronoun(Sem).\n",
        "\n",
        "% 2. M·∫°o t·ª´ + Danh t·ª´ (VD: \"m·ªôt c√¥ng ty\")\n",
        "np(Sem) --> det(Det), nn(N), { Sem = (Det @ N) }.\n",
        "\n",
        "% 3. Danh t·ª´ + T·ª´ h·ªèi (VD: \"c√¥ng ty g√¨\")\n",
        "np(Sem) --> nn(N), wp_det(Det), { Sem = (Det @ N) }.\n",
        "\n",
        "% 4. ƒê·ªìng s·ªü ch·ªâ (VD: \"anh ·∫•y\")\n",
        "np(Sem) --> nn_gender(N), det_dem(D), { Sem = (D @ N) }.\n",
        "\n",
        "% 5. Quan h·ªá (VD: \"nh√¢n vi√™n c·ªßa Samsung\")\n",
        "np(Sem) --> nn_rel(Rel), prep(_), np(Obj), { Sem = (Rel @ Obj) }.\n",
        "np(Sem) --> nn_rel(Rel), np(Obj), { Sem = (Rel @ Obj) }.\n",
        "\n",
        "\n",
        "% --- C·ª§M ƒê·ªòNG T·ª™ (VP) ---\n",
        "\n",
        "% 1. ƒê·ªông t·ª´ th∆∞·ªùng + T√¢n ng·ªØ (VD: \"gh√©t Nghƒ©a\")\n",
        "vp(Sem) --> vb(V), np(Obj), { Sem = (V @ Obj) }.\n",
        "\n",
        "% 2. ƒê·ªông t·ª´ \"L√Ä\" + C·ª•m danh t·ª´ (VD: \"l√† m·ªôt t·∫≠p ƒëo√†n\")\n",
        "% Tr∆∞·ªùng h·ª£p n√†y Obj l√† m·ªôt L∆∞·ª£ng t·ª´ (Generalized Quantifier)\n",
        "% Ta d√πng vb_be_eq ƒë·ªÉ t·∫°o quan h·ªá X = Y\n",
        "vp(Sem) --> vb_be_eq(Be), np(Obj), { Sem = (Be @ Obj) }.\n",
        "\n",
        "% 3. ƒê·ªông t·ª´ \"L√Ä\" + Danh t·ª´ ch·ªâ lo·∫°i (VD: \"l√† t·∫≠p ƒëo√†n\") -> FIX L·ªñI C·ª¶A B·∫†N\n",
        "% Tr∆∞·ªùng h·ª£p n√†y N l√† m·ªôt Thu·ªôc t√≠nh (Property/Predicate)\n",
        "% Ta d√πng vb_be_id (Identity) ƒë·ªÉ gi·ªØ nguy√™n thu·ªôc t√≠nh ƒë√≥\n",
        "vp(Sem) --> vb_be_id(Be), nn(N), { Sem = (Be @ N) }.\n",
        "\n",
        "\n",
        "% ================= T·ª™ V·ª∞NG =================\n",
        "\n",
        "% --- T√äN RI√äNG ---\n",
        "nnp(lambda(Q, drs([tu],[]) x (Q@tu))) --> [tu].\n",
        "nnp(lambda(Q, drs([nghia],[]) x (Q@nghia))) --> [nghia].\n",
        "nnp(lambda(Q, drs([samsung],[]) x (Q@samsung))) --> [samsung].\n",
        "nnp(lambda(Q, drs([apple],[]) x (Q@apple))) --> [apple].\n",
        "nnp(lambda(Q, drs([iphone],[]) x (Q@iphone))) --> [iphone].\n",
        "\n",
        "% --- T·ª™ H·ªéI ---\n",
        "wp_pronoun(lambda(Q, drs([X], [question_target(X)]) x (Q @ X))) --> [ai].\n",
        "wp_pronoun(lambda(Q, drs([X], [question_target(X)]) x (Q @ X))) --> [gi].\n",
        "wp_det(lambda(P, lambda(Q, drs([X], [question_target(X)]) x (P@X) x (Q@X)))) --> [gi].\n",
        "\n",
        "% --- DANH T·ª™ CHUNG ---\n",
        "nn(lambda(X, drs([], [cong_ty(X)]))) --> [cong_ty].\n",
        "nn(lambda(X, drs([], [tap_doan(X)]))) --> [tap_doan].\n",
        "nn(lambda(X, drs([], [dien_thoai(X)]))) --> [dien_thoai].\n",
        "\n",
        "% --- DANH T·ª™ QUAN H·ªÜ ---\n",
        "nn_rel(lambda(ObjGQ, lambda(SubjProp,\n",
        "    ObjGQ @ lambda(Y, drs([X], [nhan_vien(X,Y)]) x (SubjProp @ X))\n",
        "))) --> [nhan_vien].\n",
        "\n",
        "nn_rel(lambda(ObjGQ, lambda(SubjProp,\n",
        "    ObjGQ @ lambda(Y, drs([X], [ban(X,Y)]) x (SubjProp @ X))\n",
        "))) --> [ban].\n",
        "\n",
        "% --- ƒê·ªòNG T·ª™ ---\n",
        "vb(lambda(ObjGQ, lambda(S, ObjGQ @ lambda(O, drs([], [ghet(S,O)]))))) --> [ghet].\n",
        "vb(lambda(ObjGQ, lambda(S, ObjGQ @ lambda(O, drs([], [thich(S,O)]))))) --> [thich].\n",
        "vb(lambda(ObjGQ, lambda(S, ObjGQ @ lambda(O, drs([], [co(S,O)]))))) --> [co].\n",
        "\n",
        "% --- ƒê·ªòNG T·ª™ \"L√Ä\" (QUAN TR·ªåNG) ---\n",
        "\n",
        "% C√°ch 1: H√†m ƒë·ªìng nh·∫•t (Identity: lambda P.P)\n",
        "% D√πng cho: \"Samsung l√† t·∫≠p ƒëo√†n\" (Samsung c√≥ thu·ªôc t√≠nh t·∫≠p ƒëo√†n)\n",
        "vb_be_id(lambda(P, P)) --> [la].\n",
        "\n",
        "% C√°ch 2: Quan h·ªá b·∫±ng (Equality: X = Y)\n",
        "% D√πng cho: \"Samsung l√† m·ªôt t·∫≠p ƒëo√†n\" (T·ªìn t·∫°i X l√† t·∫≠p ƒëo√†n v√† Samsung = X)\n",
        "% Logic: lambda(GQ, lambda(S, GQ @ lambda(O, drs([], [S=O]))))\n",
        "vb_be_eq(lambda(ObjGQ, lambda(S, ObjGQ @ lambda(O, drs([], [S=O]))))) --> [la].\n",
        "\n",
        "\n",
        "% --- M·∫†O T·ª™ ---\n",
        "% \"M·ªôt\" l√† l∆∞·ª£ng t·ª´ t·ªìn t·∫°i\n",
        "det(lambda(P, lambda(Q, drs([Z], []) x (P@Z) x (Q@Z)))) --> [mot].\n",
        "\n",
        "% --- H∆Ø T·ª™ KH√ÅC ---\n",
        "nn_gender(lambda(X, drs([], [anh(X)]))) --> [anh].\n",
        "det_dem(lambda(P, lambda(Q, drs([X],[]) x (P@X) x (Q@X)))) --> [ay].\n",
        "prep(lambda(P, P)) --> [cua]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaHChZXzfIoU",
        "outputId": "4ca60970-a54e-46eb-a881-27989aded40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting test.pl\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.pl\n",
        ":- ensure_loaded('engine.pl').\n",
        ":- ensure_loaded('grammar.pl').\n",
        ":- ensure_loaded('facts.pl').\n",
        "\n",
        "% --- [QUAN TR·ªåNG] KHAI B√ÅO TO√ÅN T·ª¨ & ---\n",
        "% ƒê·ªãnh nghƒ©a & l√† to√°n t·ª≠ k·∫øt h·ª£p ph·∫£i (xfy) v·ªõi ƒë·ªô ∆∞u ti√™n 800\n",
        ":- op(800, xfy, &).\n",
        "\n",
        "% --- 1. H√ÄM CHUY·ªÇN ƒê·ªîI DRS SANG FOL ---\n",
        "\n",
        "% H√†m ph·ª•: Chuy·ªÉn danh s√°ch ƒëi·ªÅu ki·ªán th√†nh chu·ªói logic A & B & C\n",
        "list_to_and([], true).          % R·ªóng -> True\n",
        "list_to_and([One], One) :- !.   % 1 ph·∫ßn t·ª≠ -> Ch√≠nh n√≥\n",
        "list_to_and([Head|Tail], Head & Rest) :- % Nhi·ªÅu ph·∫ßn t·ª≠ -> Head & Rest\n",
        "    list_to_and(Tail, Rest).\n",
        "\n",
        "% H√†m ch√≠nh: Chuy·ªÉn ƒë·ªïi c·∫•u tr√∫c DRS -> FOL\n",
        "% Tr∆∞·ªùng h·ª£p 1: C√≥ bi·∫øn (Refs kh√°c r·ªóng) -> Th√™m l∆∞·ª£ng t·ª´ t·ªìn t·∫°i (exists)\n",
        "drs_to_fol(drs(Refs, Conds), exists(Refs, Body)) :-\n",
        "    Refs \\= [], !,\n",
        "    list_to_and(Conds, Body).\n",
        "\n",
        "% Tr∆∞·ªùng h·ª£p 2: Kh√¥ng c√≥ bi·∫øn (Refs r·ªóng) -> Ch·ªâ n·ªëi c√°c ƒëi·ªÅu ki·ªán\n",
        "drs_to_fol(drs([], Conds), Body) :-\n",
        "    list_to_and(Conds, Body).\n",
        "\n",
        "% Catch-all: N·∫øu l·ªói c·∫•u tr√∫c, tr·∫£ v·ªÅ fail ƒë·ªÉ in th√¥ng b√°o l·ªói\n",
        "drs_to_fol(_, _) :- fail.\n",
        "\n",
        "\n",
        "% --- 2. B·ªò GI·∫¢I (SOLVER) ---\n",
        "solve_drs(drs(_, Conds), TargetVars) :-\n",
        "    maplist(call, Conds),\n",
        "    findall(X, (member(question_target(X), Conds)), TargetVars).\n",
        "\n",
        "\n",
        "% --- 3. H√ÄM X·ª¨ L√ù CH√çNH (PROCESS) ---\n",
        "process_question(ListTu) :-\n",
        "    (   txt(LambdaRaw, ListTu, []),\n",
        "        reduce_fully(LambdaRaw, FinalDRS)\n",
        "    ->\n",
        "        % A. IN DRS\n",
        "        write('DRS: '), write(FinalDRS), nl,\n",
        "\n",
        "        % B. IN FOL (ƒê√£ an to√†n h∆°n)\n",
        "        (   drs_to_fol(FinalDRS, FolForm)\n",
        "        ->  write('FOL: '), write(FolForm), nl\n",
        "        ;   write('FOL: error_converting_structure'), nl\n",
        "        ),\n",
        "\n",
        "        % C. TR·∫¢ L·ªúI\n",
        "        (   solve_drs(FinalDRS, Targets),\n",
        "            ( Targets \\= [] ->\n",
        "                sort(Targets, UniqueTargets),\n",
        "                write('RESULT: '), write(UniqueTargets)\n",
        "            ;\n",
        "                write('RESULT: YES')\n",
        "            )\n",
        "        ->  true\n",
        "        ;   write('RESULT: NO')\n",
        "        )\n",
        "    ;   write('RESULT: ERROR (Khong hieu cau hoi)')\n",
        "    ),\n",
        "    halt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "i6GT6-JxhcRv",
        "outputId": "0013de5e-7445-42fe-d2e0-b4e3f6574094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://66b7033ece72eda2f5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://66b7033ece72eda2f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG Input: [tu, la, nhan_vien, cua, samsung]\n",
            "DEBUG Input: [tu, la, nhan_vien, cua, samsung]\n",
            "DEBUG Input: [tu, la, nhan_vien, cua, samsung, anh, ay, ghet, nghia]\n",
            "DEBUG Input: [tu, la, nhan_vien, cua, samsung, anh, ay, ghet, nghia]\n",
            "DEBUG Input: [tu, la, nhan_vien, cua, samsung]\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from unidecode import unidecode\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\" #ch√®n link api key\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "def get_knowledge_base():\n",
        "    try:\n",
        "        with open(\"facts.pl\", \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read()\n",
        "    except:\n",
        "        return \"anh(tu). cong_ty(samsung). nhan_vien(tu, samsung).\"\n",
        "\n",
        "\n",
        "def ask_llm_direct(question):\n",
        "    kb = get_knowledge_base()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    B·∫°n l√† m·ªôt m√°y suy lu·∫≠n logic thu·∫ßn t√∫y.\n",
        "    Nhi·ªám v·ª•: D·ª±a v√†o Knowledge Base (KB) cung c·∫•p d∆∞·ªõi ƒë√¢y, h√£y chuy·ªÉn c√¢u h·ªèi sang Logic (FOL/Prolog) v√† t√¨m ƒë√°p √°n.\n",
        "\n",
        "    === KNOWLEDGE BASE ===\n",
        "    {kb}\n",
        "    ======================\n",
        "\n",
        "    C√¢u h·ªèi: \"{question}\"\n",
        "\n",
        "    Y√™u c·∫ßu b·∫Øt bu·ªôc:\n",
        "    1. Tuy·ªát ƒë·ªëi KH√îNG gi·∫£i th√≠ch, KH√îNG n√≥i l·ªùi d·∫´n.\n",
        "    2. Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng 2 d√≤ng theo ƒë·ªãnh d·∫°ng sau:\n",
        "\n",
        "    FOL: <bi·ªÉu th·ª©c logic ho·∫∑c prolog query t∆∞∆°ng ·ª©ng>\n",
        "    ANSWER: <YES / NO / Danh s√°ch k·∫øt qu·∫£ d·∫°ng [a, b]>\n",
        "\n",
        "    3. QUY T·∫ÆC QUAN TR·ªåNG V·ªöI T·ª™ \"L√Ä\":\n",
        "       - V·ªõi c√¢u d·∫°ng \"A l√† B\" (ƒë·ªãnh danh/ph√¢n lo·∫°i), h√£y d√πng v·ªã t·ª´ m·ªôt ng√¥i B(A).\n",
        "       - V√≠ d·ª•: \"Samsung l√† t·∫≠p ƒëo√†n\" => tap_doan(samsung).\n",
        "       - TUY·ªÜT ƒê·ªêI KH√îNG VI·∫æT: la(samsung, tap_doan).\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        return \"ü§ñ LLM (Direct Logic):\\n\" + content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"L·ªói g·ªçi LLM: {str(e)}\"\n",
        "\n",
        "COMPOUND_WORDS = {\n",
        "    \"c√¥ng ty\": \"cong_ty\", \"t·∫≠p ƒëo√†n\": \"tap_doan\", \"ƒëi·ªán tho·∫°i\": \"dien_thoai\",\n",
        "    \"nh√¢n vi√™n\": \"nhan_vien\", \"b·∫°n b√®\": \"ban\"\n",
        "}\n",
        "STOP_WORDS = [\"phai khong\", \"khong\", \"ha\", \"nhi\", \"a\", \"u\", \"chua\", \"roi\"]\n",
        "MAIN_VERBS = [\"ghet\", \"thich\", \"yeu\", \"la\"]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text_no_accent = unidecode(text).lower()\n",
        "    text_clean = re.sub(r'[^\\w\\s]', '', text_no_accent)\n",
        "    for word, replacement in COMPOUND_WORDS.items():\n",
        "        text_clean = text_clean.replace(unidecode(word).lower(), replacement)\n",
        "    for stop_word in STOP_WORDS:\n",
        "        text_clean = re.sub(r'\\b' + stop_word + r'\\b', '', text_clean)\n",
        "    tokens = text_clean.split()\n",
        "    final_tokens = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token == \"co\":\n",
        "            if i + 1 < len(tokens) and tokens[i+1] in MAIN_VERBS: continue\n",
        "        final_tokens.append(token)\n",
        "    return \"[\" + \", \".join(final_tokens) + \"]\"\n",
        "\n",
        "def toString(d):\n",
        "    OPS = [\"&\", \"v\", \"=>\", \"<=>\", \"@\", \"x\"]\n",
        "    if type(d) is dict:\n",
        "        functor = d.get(\"functor\")\n",
        "        args = d.get(\"args\")\n",
        "        if functor in OPS:\n",
        "            st = [toString(args[0]), \"{}\".format(functor)]\n",
        "            for e in args[1:]: st.append(toString(e))\n",
        "            return \" \".join(st)\n",
        "        elif functor == \"exists\":\n",
        "            return f\"‚àÉ{args[0]} ({toString(args[1])})\"\n",
        "        else:\n",
        "            st = [\"{}({}\".format(functor, toString(args[0]))]\n",
        "            for e in args[1:]: st.append(\"{}\".format(toString(e)))\n",
        "            return \",\".join(st) + \")\"\n",
        "    return \"{}\".format(d)\n",
        "\n",
        "def parse_fol_string(text):\n",
        "    text = text.strip()\n",
        "    exists_match = re.match(r'exists\\(([\\w\\[\\],_ ]+),\\s*(.*)\\)$', text)\n",
        "    if exists_match:\n",
        "        return {\"functor\": \"exists\", \"args\": [exists_match.group(1).strip(), parse_fol_string(exists_match.group(2).strip())]}\n",
        "    if '&' in text:\n",
        "        return {\"functor\": \"&\", \"args\": [parse_fol_string(p) for p in text.split('&')]}\n",
        "    match = re.match(r'(\\w+)\\((.*)\\)', text)\n",
        "    if match:\n",
        "        return {\"functor\": match.group(1), \"args\": [a.strip() for a in match.group(2).split(',')]}\n",
        "    return text\n",
        "\n",
        "def ask_prolog_pipeline(question):\n",
        "    try:\n",
        "        prolog_list = preprocess_text(question)\n",
        "        print(f\"DEBUG Input: {prolog_list}\")\n",
        "        command = f\"swipl -s test.pl -g \\\"process_question({prolog_list})\\\"\"\n",
        "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "        drs_match = re.search(r'DRS: (.*)', result.stdout)\n",
        "        fol_match = re.search(r'FOL: (.*)', result.stdout)\n",
        "        ans_match = re.search(r'RESULT: (.*)', result.stdout)\n",
        "\n",
        "        drs_text = drs_match.group(1).strip() if drs_match else \"...\"\n",
        "        fol_raw = fol_match.group(1).strip() if fol_match else \"...\"\n",
        "\n",
        "        try:\n",
        "            if fol_raw != \"...\" and \"error\" not in fol_raw:\n",
        "                fol_pretty = toString(parse_fol_string(fol_raw))\n",
        "            else: fol_pretty = fol_raw\n",
        "        except: fol_pretty = fol_raw\n",
        "\n",
        "        if ans_match:\n",
        "            ans = ans_match.group(1).strip()\n",
        "            final_ans = \"YES\" if ans == \"YES\" else (\"NO\" if ans == \"NO\" else ans)\n",
        "            return (f\"ƒê√°p √°n: {final_ans}\\n\\n\"\n",
        "                    f\"DRS Raw:\\n{drs_text}\\n\\n\"\n",
        "                    f\"FOL Structure:\\n{fol_pretty}\")\n",
        "        else:\n",
        "            return f\"‚ö†Ô∏è L·ªói x·ª≠ l√Ω: {result.stdout}\"\n",
        "    except Exception as e: return f\"L·ªói: {str(e)}\"\n",
        "\n",
        "def main_handler(question, mode):\n",
        "    if mode == \"Prolog Pipeline\":\n",
        "        return ask_prolog_pipeline(question)\n",
        "    else:\n",
        "        return ask_llm_direct(question)\n",
        "\n",
        "with gr.Blocks(title=\"Computational Semantics Demo\") as demo:\n",
        "    gr.Markdown(\"# ü§ñ H·ªá Th·ªëng H·ªèi ƒê√°p: Logic vs LLM\")\n",
        "    gr.Markdown(\"Ch·ªçn ph∆∞∆°ng ph√°p x·ª≠ l√Ω b√™n d∆∞·ªõi:\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            radio = gr.Radio(\n",
        "                [\"Prolog Pipeline\", \"LLM\"],\n",
        "                label=\"Ch·∫ø ƒë·ªô x·ª≠ l√Ω\",\n",
        "                value=\"Prolog Pipeline\"\n",
        "            )\n",
        "            inp = gr.Textbox(label=\"C√¢u h·ªèi\", placeholder=\"V√≠ d·ª•: Ai l√† nh√¢n vi√™n c·ªßa Samsung?\")\n",
        "            btn = gr.Button(\"G·ª≠i c√¢u h·ªèi\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            out = gr.Textbox(label=\"K·∫øt qu·∫£ chi ti·∫øt\", lines=12)\n",
        "\n",
        "    btn.click(fn=main_handler, inputs=[inp, radio], outputs=out)\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
